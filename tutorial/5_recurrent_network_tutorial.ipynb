{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ji2kWSDgbop"
      },
      "source": [
        "# Recurrent network and dynamics activity\n",
        "In this activity you will train a LSTM network to approximate a certain nonlinear dynamic system. The system is a van der Pol oscillator. It has has two state variables, which we can call $x_1$ and $x_2$. The state variables change over time in a way that depends on the state variables themselves. Specifically, \n",
        "\\begin{align*}\n",
        "\\dot{x}_1 &= x_2 \\\\\n",
        "\\dot{x}_2 &= \\mu (1-x_1^2) x_2 - x_1 \n",
        "\\end{align*}\n",
        "where $\\mu>0$ is a parameter. Trajectories of the state variables can be plotted in a flow field, like so ... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qrWnGzwrlSd5",
        "outputId": "ef919954-2bf5-419b-e076-5197b76d3d31"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_flow_field():\n",
        "    x1 = np.linspace(-5, 5, 20)\n",
        "    x2 = np.linspace(-5, 5, 20)\n",
        "    X1, X2 = np.meshgrid(x1, x2)\n",
        "\n",
        "    mu = 0.1\n",
        "    dx1 = X2\n",
        "    dx2 = mu * (1-X1**2) * X2 - X1\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    plt.streamplot(X1, X2, dx1, dx2, density=1)\n",
        "\n",
        "plot_flow_field()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I50O0fQKlmnW"
      },
      "source": [
        "This system is a kind of limit-cycle oscillator. It is an oscillator because the state-variable trajectories go around in loops. It is a limit-cycle oscillator because all of its trajectories (starting from any state) converge to the same loop (called the limit cycle). Trajectories starting near the centre gradually spiral out while those starting farther out gradually spiral in until they all end up on the same cycle. \n",
        "\n",
        "To simulate a single trajectory of the system from a given starting state, we can use a standard differential equation solver from Scipy. To do this, we have to implement the right-hand side of the dynamic equations as a Python function. Let's do that and plot a state trajectory two seconds long starting from a random state. We will overlay it on the flow field to confirm that the trajectory follows the flow field.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "3zVnP158maBP",
        "outputId": "7228aa9d-12db-4253-cae8-46f572a27602"
      },
      "outputs": [],
      "source": [
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "def van_der_pol_dynamics(t, x):\n",
        "    \"\"\"    \n",
        "    :param t: time (not used, but the solver expects a function with this argument)  \n",
        "    :param x: state vector \n",
        "    :return: state derivative vector \n",
        "    \"\"\"\n",
        "\n",
        "    mu = 0.1\n",
        "    dx1 = x[1]\n",
        "    dx2 = mu * (1 - x[0] ** 2) * x[1] - x[0]\n",
        "    return [dx1, dx2]\n",
        "\n",
        "x0 = -5 + 10*np.random.rand(2)\n",
        "solution = solve_ivp(van_der_pol_dynamics, [0, 2], x0, max_step=.1)\n",
        "\n",
        "plot_flow_field()\n",
        "plt.plot(solution.y[0,:], solution.y[1,:])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcbqiDkkqiDv"
      },
      "source": [
        "We will train a LSTM neural network to approximate these dynamics. To do this we will need batches of random example trajectories. The following code will produce those. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7bN-dLyqwrB"
      },
      "outputs": [],
      "source": [
        "def get_random_trajectory():\n",
        "    \"\"\"\n",
        "    :return: a van der Pol trajectory from a random initial state\n",
        "    \"\"\"\n",
        "    dt = .1\n",
        "    T = 2\n",
        "    x0 = -5 + 10*np.random.rand(2)\n",
        "    solution = solve_ivp(van_der_pol_dynamics, [0, T], x0, max_step=dt)\n",
        "\n",
        "    # Here we do some extra work to make sure all trajectories have the same \n",
        "    # number of samples (solve_ivp doesn't guarantee that). \n",
        "    times = np.linspace(0, T, int(T/dt)+1)\n",
        "    trajectory = np.zeros((2,len(times)))\n",
        "    trajectory[0,:] = np.interp(times, solution.t, solution.y[0,:])\n",
        "    trajectory[1,:] = np.interp(times, solution.t, solution.y[1,:])\n",
        "\n",
        "    return trajectory\n",
        "\n",
        "\n",
        "\n",
        "def get_minibatch(n):\n",
        "    \"\"\"\n",
        "    :param n: number of examples in minibatch\n",
        "    :return: minibatch of van der Pol trajectories from random initial states\n",
        "    \"\"\"\n",
        "    inputs = []\n",
        "    trajectories = []\n",
        "    for i in range(n):\n",
        "        trajectory = get_random_trajectory()\n",
        "        x0 = trajectory[:, 0]\n",
        "        input = np.zeros_like(trajectory)\n",
        "        input[:,0] = x0\n",
        "        inputs.append(input.T)\n",
        "        trajectories.append(trajectory.T)\n",
        "    inputs = np.array(inputs).swapaxes(0, 1) # axis order: [sequence, minibatch, elements]\n",
        "    trajectories = np.array(trajectories).swapaxes(0, 1)\n",
        "    return torch.Tensor(inputs), torch.Tensor(trajectories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXJiXsNHs0a-"
      },
      "source": [
        "We have set this up so that the input to the network in the first step is the starting state and the target is the full trajectory. \n",
        "Now we will make an LSTM network using a torch.nn.LSTM layer for dynamics and a torch.nn.Linear layer to decode the two-dimensional state from the network's hidden variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAfqfteftfIA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, target_dim):\n",
        "        super(LSTMNetwork, self).__init__()\n",
        "        #TODO: complete this method \n",
        "\n",
        "    def forward(self, input):\n",
        "        #TODO: complete this method \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIL8cvsGtxsZ"
      },
      "source": [
        "Now let's make one of these networks and train it to be a van der Pol oscillator. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imciL-m8t-x9",
        "outputId": "b4f2e00f-71aa-4895-dfa9-9171df3aded1"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "# TODO: create a network with 20 hidden units  \n",
        "# TODO: create a SGD optimizer with learning rate 0.05\n",
        "\n",
        "running_loss = 0\n",
        "for sample in range(2000):\n",
        "    model.zero_grad()\n",
        "\n",
        "    initial_conditions, trajectories = get_minibatch(20)\n",
        "\n",
        "    #TODO: run the model and calculate the loss (use the variable name \"loss\") \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # calculate and periodically loss that is smoothed over time \n",
        "    running_loss = .9*running_loss + .1*loss.item()\n",
        "    if sample % 50 == 49:\n",
        "        print('Batch #{}  Loss {}'.format(sample+1, running_loss))\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVnPTVw7uE0U"
      },
      "source": [
        "Finally we sould see how well the network does at pretending to be a van der Pol oscillator. Plot the flow field again along with trajectories from one minibatch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JFuXdG5QuTZD",
        "outputId": "b9a903a9-7d96-4060-8c9b-0125549c3538"
      },
      "outputs": [],
      "source": [
        "plot_flow_field()\n",
        "\n",
        "initial_conditions, trajectories = get_minibatch(20)\n",
        "output = model(initial_conditions).detach().numpy()\n",
        "for i in range(output.shape[1]):\n",
        "    trajectory = output[:,i,:]\n",
        "    plt.plot(trajectory[:,0], trajectory[:,1])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6-PknfLvMU3"
      },
      "source": [
        "The network struggles at the beginning of a trajectory. This will improve if you train the network for longer. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
